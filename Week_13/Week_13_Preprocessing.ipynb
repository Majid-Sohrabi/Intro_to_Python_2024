{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8ShhvetFpA7"
   },
   "source": [
    "# Week 13: Preprocessing\n",
    "\n",
    "Source: [MNE-Python](https://mne.tools/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview of artifact detection\n",
    "\n",
    "This tutorial covers the basics of artifact detection, and introduces the\n",
    "artifact detection tools available in MNE-Python.\n",
    "\n",
    "We begin as always by importing the necessary Python modules and loading some\n",
    "`example data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "\n",
    "sample_data_folder = mne.datasets.sample.data_path()\n",
    "sample_data_raw_file = os.path.join(\n",
    "    sample_data_folder, \"MEG\", \"sample\", \"sample_audvis_raw.fif\"\n",
    ")\n",
    "raw = mne.io.read_raw_fif(sample_data_raw_file)\n",
    "raw.crop(0, 60).load_data()  # just use a fraction of data for speed here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are artifacts?\n",
    "\n",
    "Artifacts are parts of the recorded signal that arise from sources other than\n",
    "the source of interest (i.e., neuronal activity in the brain). As such,\n",
    "artifacts are a form of interference or noise relative to the signal of\n",
    "interest. There are many possible causes of such interference, for example:\n",
    "\n",
    "- Environmental artifacts\n",
    "    - Persistent oscillations centered around the `AC power line frequency`_\n",
    "      (typically 50 or 60 Hz)\n",
    "    - Brief signal jumps due to building vibration (such as a door slamming)\n",
    "    - Electromagnetic field noise from nearby elevators, cell phones, the\n",
    "      geomagnetic field, etc.\n",
    "\n",
    "- Instrumentation artifacts\n",
    "    - Electromagnetic interference from stimulus presentation (such as EEG\n",
    "      sensors picking up the field generated by unshielded headphones)\n",
    "    - Continuous oscillations at specific frequencies used by head position\n",
    "      indicator (HPI) coils\n",
    "    - Random high-amplitude fluctuations (or alternatively, constant zero\n",
    "      signal) in a single channel due to sensor malfunction (e.g., in surface\n",
    "      electrodes, poor scalp contact)\n",
    "\n",
    "- Biological artifacts\n",
    "    - Periodic `QRS`_-like signal patterns (especially in magnetometer\n",
    "      channels) due to electrical activity of the heart\n",
    "    - Short step-like deflections (especially in frontal EEG channels) due to\n",
    "      eye movements\n",
    "    - Large transient deflections (especially in frontal EEG channels) due to\n",
    "      blinking\n",
    "    - Brief bursts of high frequency fluctuations across several channels due\n",
    "      to the muscular activity during swallowing\n",
    "\n",
    "There are also some cases where signals from within the brain can be\n",
    "considered artifactual. For example, if a researcher is primarily interested\n",
    "in the sensory response to a stimulus, but the experimental paradigm involves\n",
    "a behavioral response (such as button press), the neural activity associated\n",
    "with the planning and executing the button press could be considered an\n",
    "artifact relative to signal of interest (i.e., the evoked sensory response).\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Artifacts of the same genesis may appear different in recordings made by\n",
    "    different EEG or MEG systems, due to differences in sensor design (e.g.,\n",
    "    passive vs. active EEG electrodes; axial vs. planar gradiometers, etc).</p></div>\n",
    "\n",
    "\n",
    "## What to do about artifacts\n",
    "\n",
    "There are 3 basic options when faced with artifacts in your recordings:\n",
    "\n",
    "1. *Ignore* the artifact and carry on with analysis\n",
    "2. *Exclude* the corrupted portion of the data and analyze the remaining data\n",
    "3. *Repair* the artifact by suppressing artifactual part of the recording\n",
    "   while (hopefully) leaving the signal of interest intact\n",
    "\n",
    "There are many different approaches to repairing artifacts, and MNE-Python\n",
    "includes a variety of tools for artifact repair, including digital filtering,\n",
    "independent components analysis (ICA), Maxwell filtering / signal-space\n",
    "separation (SSS), and signal-space projection (SSP). Separate tutorials\n",
    "demonstrate each of these techniques for artifact repair. Many of the\n",
    "artifact repair techniques work on both continuous (raw) data and on data\n",
    "that has already been epoched (though not necessarily equally well); some can\n",
    "be applied to `memory-mapped`_ data while others require the data to be\n",
    "copied into RAM. Of course, before you can choose any of these strategies you\n",
    "must first *detect* the artifacts, which is the topic of the next section.\n",
    "\n",
    "\n",
    "## Artifact detection\n",
    "\n",
    "MNE-Python includes a few tools for automated detection of certain artifacts\n",
    "(such as heartbeats and blinks), but of course you can always visually\n",
    "inspect your data to identify and annotate artifacts as well.\n",
    "\n",
    "We saw in `the introductory tutorial <tut-overview>` that the example\n",
    "data includes :term:`SSP projectors <projector>`, so before we look at\n",
    "artifacts let's set aside the projectors in a separate variable and then\n",
    "remove them from the :class:`~mne.io.Raw` object using the\n",
    ":meth:`~mne.io.Raw.del_proj` method, so that we can inspect our data in it's\n",
    "original, raw state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp_projectors = raw.info[\"projs\"]\n",
    "raw.del_proj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-frequency drifts\n",
    "\n",
    "Low-frequency drifts are most readily detected by visual inspection using the\n",
    "basic :meth:`~mne.io.Raw.plot` method, though it is helpful to plot a\n",
    "relatively long time span and to disable channel-wise DC shift correction.\n",
    "Here we plot 60 seconds and show all the magnetometer channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_channels = mne.pick_types(raw.info, meg=\"mag\")\n",
    "raw.plot(duration=60, order=mag_channels, n_channels=len(mag_channels), remove_dc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low-frequency drifts are readily removed by high-pass filtering at a fairly\n",
    "low cutoff frequency (the wavelength of the drifts seen above is probably\n",
    "around 20 seconds, so in this case a cutoff of 0.1 Hz would probably suppress\n",
    "most of the drift).\n",
    "\n",
    "### Power line noise\n",
    "\n",
    "Power line artifacts are easiest to see on plots of the spectrum, so we'll\n",
    "use :meth:`~mne.io.Raw.compute_psd` to illustrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = raw.compute_psd(tmax=np.inf, fmax=250).plot(\n",
    "    average=True, amplitude=False, picks=\"data\", exclude=\"bads\"\n",
    ")\n",
    "# add some arrows at 60 Hz and its harmonics:\n",
    "for ax in fig.axes[1:]:\n",
    "    freqs = ax.lines[-1].get_xdata()\n",
    "    psds = ax.lines[-1].get_ydata()\n",
    "    for freq in (60, 120, 180, 240):\n",
    "        idx = np.searchsorted(freqs, freq)\n",
    "        ax.arrow(\n",
    "            x=freqs[idx],\n",
    "            y=psds[idx] + 18,\n",
    "            dx=0,\n",
    "            dy=-12,\n",
    "            color=\"red\",\n",
    "            width=0.1,\n",
    "            head_width=3,\n",
    "            length_includes_head=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see narrow frequency peaks at 60, 120, 180, and 240 Hz â€” the power\n",
    "line frequency of the USA (where the sample data was recorded) and its 2nd,\n",
    "3rd, and 4th harmonics. Other peaks (around 25 to 30 Hz, and the second\n",
    "harmonic of those) are probably related to the heartbeat, which is more\n",
    "easily seen in the time domain using a dedicated heartbeat detection function\n",
    "as described in the next section.\n",
    "\n",
    "### Heartbeat artifacts (ECG)\n",
    "\n",
    "MNE-Python includes a dedicated function\n",
    ":func:`~mne.preprocessing.find_ecg_events` in the :mod:`mne.preprocessing`\n",
    "submodule, for detecting heartbeat artifacts from either dedicated ECG\n",
    "channels or from magnetometers (if no ECG channel is present). Additionally,\n",
    "the function :func:`~mne.preprocessing.create_ecg_epochs` will call\n",
    ":func:`~mne.preprocessing.find_ecg_events` under the hood, and use the\n",
    "resulting events array to extract epochs centered around the detected\n",
    "heartbeat artifacts. Here we create those epochs, then show an image plot of\n",
    "the detected ECG artifacts along with the average ERF across artifacts. We'll\n",
    "show all three channel types, even though EEG channels are less strongly\n",
    "affected by heartbeat artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_epochs = mne.preprocessing.create_ecg_epochs(raw)\n",
    "ecg_epochs.plot_image(combine=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The horizontal streaks in the magnetometer image plot reflect the fact that\n",
    "the heartbeat artifacts are superimposed on low-frequency drifts like the one\n",
    "we saw in an earlier section; to avoid this you could pass\n",
    "``baseline=(-0.5, -0.2)`` in the call to\n",
    ":func:`~mne.preprocessing.create_ecg_epochs`.\n",
    "You can also get a quick look at the\n",
    "ECG-related field pattern across sensors by averaging the ECG epochs together\n",
    "via the :meth:`~mne.Epochs.average` method, and then using the\n",
    ":meth:`mne.Evoked.plot_topomap` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ecg_epochs = ecg_epochs.average().apply_baseline((-0.5, -0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here again we can visualize the spatial pattern of the associated field at\n",
    "various times relative to the peak of the EOG response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ecg_epochs.plot_topomap(times=np.linspace(-0.05, 0.05, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can get an ERP/F plot with :meth:`~mne.Evoked.plot` or a combined\n",
    "scalp field maps and ERP/F plot with :meth:`~mne.Evoked.plot_joint`. Here\n",
    "we've specified the times for scalp field maps manually, but if not provided\n",
    "they will be chosen automatically based on peaks in the signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ecg_epochs.plot_joint(times=[-0.25, -0.025, 0, 0.025, 0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ocular artifacts (EOG)\n",
    "\n",
    "Similar to the ECG detection and epoching methods described above, MNE-Python\n",
    "also includes functions for detecting and extracting ocular artifacts:\n",
    ":func:`~mne.preprocessing.find_eog_events` and\n",
    ":func:`~mne.preprocessing.create_eog_epochs`. Once again we'll use the\n",
    "higher-level convenience function that automatically finds the artifacts and\n",
    "extracts them in to an :class:`~mne.Epochs` object in one step. Unlike the\n",
    "heartbeat artifacts seen above, ocular artifacts are usually most prominent\n",
    "in the EEG channels, but we'll still show all three channel types. We'll use\n",
    "the ``baseline`` parameter this time too; note that there are many fewer\n",
    "blinks than heartbeats, which makes the image plots appear somewhat blocky:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eog_epochs = mne.preprocessing.create_eog_epochs(raw, baseline=(-0.5, -0.2))\n",
    "eog_epochs.plot_image(combine=\"mean\")\n",
    "eog_epochs.average().plot_joint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Handling bad channels\n",
    "\n",
    "This tutorial covers manual marking of bad channels and reconstructing bad channels based on good signals at other sensors.\n",
    "\n",
    "As usual weâ€™ll start by importing the modules we need, and loading some example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "\n",
    "sample_data_folder = mne.datasets.sample.data_path()\n",
    "sample_data_raw_file = os.path.join(\n",
    "    sample_data_folder, \"MEG\", \"sample\", \"sample_audvis_raw.fif\"\n",
    ")\n",
    "raw = mne.io.read_raw_fif(sample_data_raw_file, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marking bad channels\n",
    "\n",
    "Sometimes individual channels malfunction and provide data that is too noisy\n",
    "to be usable. MNE-Python makes it easy to ignore those channels in the\n",
    "analysis stream without actually deleting the data in those channels. It does\n",
    "this by\n",
    "keeping track of the bad channel indices in a list and looking at that list\n",
    "when doing analysis or plotting tasks. The list of bad channels is stored in\n",
    "the ``'bads'`` field of the :class:`~mne.Info` object that is attached to\n",
    ":class:`~mne.io.Raw`, :class:`~mne.Epochs`, and :class:`~mne.Evoked` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.info[\"bads\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see that the :file:`.fif` file we loaded from disk must have\n",
    "been keeping track of channels marked as \"bad\" â€” which is good news, because\n",
    "it means any changes we make to the list of bad channels will be preserved if\n",
    "we save our data at intermediate stages and re-load it later. Since we saw\n",
    "above that ``EEG 053`` is one of the bad channels, let's look at it alongside\n",
    "some other EEG channels to see what's bad about it. We can do this using the\n",
    "standard :meth:`~mne.io.Raw.plot` method, and instead of listing the channel\n",
    "names one by one (``['EEG 050', 'EEG 051', ...]``) we'll use a `regular\n",
    "expression`_ to pick all the EEG channels between 050 and 059 with the\n",
    ":func:`~mne.pick_channels_regexp` function (the ``.`` is a wildcard\n",
    "character):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks = mne.pick_channels_regexp(raw.ch_names, regexp=\"EEG 05.\")\n",
    "raw.plot(order=picks, n_channels=len(picks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same thing for the bad MEG channel (``MEG 2443``). Since we\n",
    "know that Neuromag systems (like the one used to record the example data) use\n",
    "the last digit of the MEG channel number to indicate sensor type, here our\n",
    "`regular expression`_ will pick all the channels that start with 2 and end\n",
    "with 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks = mne.pick_channels_regexp(raw.ch_names, regexp=\"MEG 2..3\")\n",
    "raw.plot(order=picks, n_channels=len(picks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice first of all that the channels marked as \"bad\" are plotted in a light\n",
    "gray color in a layer behind the other channels, to make it easy to\n",
    "distinguish them from \"good\" channels. The plots make it clear that ``EEG\n",
    "053`` is not picking up scalp potentials at all, and ``MEG 2443`` looks like\n",
    "it's got a lot more internal noise than its neighbors â€” its signal is a few\n",
    "orders of magnitude greater than the other MEG channels, making it a clear\n",
    "candidate for exclusion.\n",
    "\n",
    "If you want to change which channels are marked as bad, you can edit\n",
    "``raw.info['bads']`` directly; it's an ordinary Python :class:`list` so the\n",
    "usual list methods will work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_bads = deepcopy(raw.info[\"bads\"])\n",
    "raw.info[\"bads\"].append(\"EEG 050\")  # add a single channel\n",
    "raw.info[\"bads\"].extend([\"EEG 051\", \"EEG 052\"])  # add a list of channels\n",
    "bad_chan = raw.info[\"bads\"].pop(-1)  # remove the last entry in the list\n",
    "raw.info[\"bads\"] = original_bads  # change the whole list at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Blocking execution\n",
    "```\n",
    "    If you want to build an interactive bad-channel-marking step into an\n",
    "    analysis script, be sure to include the parameter ``block=True`` in your\n",
    "    call to ``raw.plot()`` or ``epochs.plot()``. This will pause the script\n",
    "    while the plot is open, giving you time to mark bad channels before\n",
    "    subsequent analysis or plotting steps are executed. This can be\n",
    "    especially helpful if your script loops over multiple subjects.\n",
    "```\n",
    "\n",
    "You can also interactively toggle whether a channel is marked \"bad\" in the\n",
    "plot windows of ``raw.plot()`` or ``epochs.plot()`` by clicking on the\n",
    "channel name along the vertical axis (in ``raw.plot()`` windows you can also\n",
    "do this by clicking the channel's trace in the plot area). The ``bads`` field\n",
    "gets updated immediately each time you toggle a channel, and will retain its\n",
    "modified state after the plot window is closed.\n",
    "\n",
    "The list of bad channels in the :class:`mne.Info` object's ``bads`` field is\n",
    "automatically taken into account in dozens of functions and methods across\n",
    "the MNE-Python codebase. This is done consistently with a parameter\n",
    "``exclude='bads'`` in the function or method signature. Typically this\n",
    "``exclude`` parameter also accepts a list of channel names or indices, so if\n",
    "you want to *include* the bad channels you can do so by passing\n",
    "``exclude=[]`` (or some other list of channels to exclude). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default is exclude='bads':\n",
    "good_eeg = mne.pick_types(raw.info, meg=False, eeg=True)\n",
    "all_eeg = mne.pick_types(raw.info, meg=False, eeg=True, exclude=[])\n",
    "print(np.setdiff1d(all_eeg, good_eeg))\n",
    "print(np.array(raw.ch_names)[np.setdiff1d(all_eeg, good_eeg)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to look for bad channels\n",
    "\n",
    "You can start looking for bad channels during the experiment session when the\n",
    "data is being acquired. If you notice any flat or excessively noisy channels,\n",
    "you can note them in your experiment log or protocol sheet. If your system\n",
    "computes online averages, these can be a good way to spot bad channels as\n",
    "well. After the data has been collected, you can do a more thorough check for\n",
    "bad channels by browsing the raw data using :meth:`mne.io.Raw.plot`, without\n",
    "any projectors or ICA applied. Finally, you can compute offline averages\n",
    "(again with projectors, ICA, and EEG referencing disabled) to look for\n",
    "channels with unusual properties. Here's an example of ERP/F plots where the\n",
    "bad channels were not properly marked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2 = raw.copy()\n",
    "raw2.info[\"bads\"] = []\n",
    "events = mne.find_events(raw2, stim_channel=\"STI 014\")\n",
    "epochs = mne.Epochs(raw2, events=events)[\"2\"].average().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bad EEG channel is not so obvious, but the bad gradiometer is easy to\n",
    "see.\n",
    "\n",
    "Remember, marking bad channels should be done as early as possible in the\n",
    "analysis pipeline. When bad channels are marked in a :class:`~mne.io.Raw`\n",
    "object, the markings will be automatically transferred through the chain of\n",
    "derived object types: including :class:`~mne.Epochs` and :class:`~mne.Evoked`\n",
    "objects, but also :class:`noise covariance <mne.Covariance>` objects,\n",
    ":class:`forward solution computations <mne.Forward>`, :class:`inverse\n",
    "operators <mne.minimum_norm.InverseOperator>`, etc. If you don't notice the\n",
    "badness until later stages of your analysis pipeline, you'll probably need to\n",
    "go back and re-run the pipeline, so it's a good investment of time to\n",
    "carefully explore the data for bad channels early on.\n",
    "\n",
    "\n",
    "### Why mark bad channels at all?\n",
    "\n",
    "Many analysis computations can be strongly affected by the presence of bad\n",
    "channels. For example, a malfunctioning channel with completely flat signal\n",
    "will have zero channel variance, which will cause noise estimates to be\n",
    "unrealistically low. This low noise estimate will lead to a strong channel\n",
    "weight in the estimate of cortical current, and because the channel is flat,\n",
    "the magnitude of cortical current estimates will shrink dramatically.\n",
    "\n",
    "Conversely, very noisy channels can also cause problems. For example, they\n",
    "can lead to too many epochs being discarded based on signal amplitude\n",
    "rejection thresholds, which in turn can lead to less robust estimation of the\n",
    "noise covariance across sensors. Noisy channels can also interfere with\n",
    ":term:`SSP` computations, because the projectors will be\n",
    "spatially biased in the direction of the noisy channel, which can cause\n",
    "adjacent good channels to be suppressed. ICA is corrupted by noisy channels\n",
    "for similar reasons. On the other hand, when performing machine learning\n",
    "analyses, bad channels may have limited, if any impact (i.e., bad channels\n",
    "will be uninformative and therefore ignored / deweighted by the algorithm).\n",
    "\n",
    "\n",
    "## Interpolating bad channels\n",
    "\n",
    "In some cases simply excluding bad channels is sufficient (for example, if\n",
    "you plan only to analyze a specific sensor ROI, and the bad channel is\n",
    "outside that ROI). However, in cross-subject analyses it is often helpful to\n",
    "maintain the same data dimensionality for all subjects, and there is no\n",
    "guarantee that the same channels will be bad for all subjects. It is possible\n",
    "in such cases to remove each channel that is bad for even a single subject,\n",
    "but that can lead to a dramatic drop in data rank (and ends up discarding a\n",
    "fair amount of clean data in the process). In such cases it is desirable to\n",
    "reconstruct bad channels by interpolating its signal based on the signals of\n",
    "the good sensors around them.\n",
    "\n",
    "\n",
    "### How interpolation works\n",
    "\n",
    "Interpolation of EEG channels in MNE-Python is done using the spherical\n",
    "spline method :footcite:`PerrinEtAl1989`, which projects the sensor\n",
    "locations onto a unit sphere\n",
    "and interpolates the signal at the bad sensor locations based on the signals\n",
    "at the good locations. Mathematical details are presented in\n",
    "`channel-interpolation`. Interpolation of MEG channels uses the field\n",
    "mapping algorithms used in computing the `forward solution\n",
    "<tut-forward>`.\n",
    "\n",
    "\n",
    "### Interpolation in MNE-Python\n",
    "\n",
    "Interpolating bad channels in :class:`~mne.io.Raw` objects is done with the\n",
    ":meth:`~mne.io.Raw.interpolate_bads` method, which automatically applies the\n",
    "correct method (spherical splines or field interpolation) to EEG and MEG\n",
    "channels, respectively (there is a corresponding method\n",
    ":meth:`mne.Epochs.interpolate_bads` that works for :class:`~mne.Epochs`\n",
    "objects). To illustrate how it works, we'll start by cropping the raw object\n",
    "to just three seconds for easier plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.crop(tmin=0, tmax=3).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, :meth:`~mne.io.Raw.interpolate_bads` will clear out\n",
    "``raw.info['bads']`` after interpolation, so that the interpolated channels\n",
    "are no longer excluded from subsequent computations. Here, for illustration\n",
    "purposes, we'll prevent that by specifying ``reset_bads=False`` so that when\n",
    "we plot the data before and after interpolation, the affected channels will\n",
    "still plot in red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data = raw.copy().pick(picks=\"eeg\")\n",
    "eeg_data_interp = eeg_data.copy().interpolate_bads(reset_bads=False)\n",
    "\n",
    "for title, data in zip([\"orig.\", \"interp.\"], [eeg_data, eeg_data_interp]):\n",
    "    with mne.viz.use_browser_backend(\"matplotlib\"):\n",
    "        fig = data.plot(butterfly=True, color=\"#00000022\", bad_color=\"r\")\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    fig.suptitle(title, size=\"xx-large\", weight=\"bold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the method :meth:`~mne.io.Raw.pick` default\n",
    "arguments includes ``exclude=()`` which ensures that bad\n",
    "channels are not\n",
    "automatically dropped from the selection. Here is the corresponding example\n",
    "with the interpolated gradiometer channel; since there are more channels\n",
    "we'll use a more transparent gray color this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_data = raw.copy().pick(picks=\"grad\")\n",
    "grad_data_interp = grad_data.copy().interpolate_bads(reset_bads=False)\n",
    "\n",
    "for data in (grad_data, grad_data_interp):\n",
    "    data.plot(butterfly=True, color=\"#00000009\", bad_color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rejecting bad data spans and breaks\n",
    "\n",
    "This tutorial covers:\n",
    "\n",
    "- manual marking of bad spans of data,\n",
    "- automated rejection of data spans based on signal amplitude, and\n",
    "- automated detection of breaks during an experiment.\n",
    "\n",
    "We begin as always by importing the necessary Python modules and loading some\n",
    "`example data <sample-dataset>`; to save memory we'll use a pre-filtered\n",
    "and downsampled version of the example data, and we'll also load an events\n",
    "array to use when converting the continuous data to epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "\n",
    "sample_data_folder = mne.datasets.sample.data_path()\n",
    "sample_data_raw_file = os.path.join(\n",
    "    sample_data_folder, \"MEG\", \"sample\", \"sample_audvis_filt-0-40_raw.fif\"\n",
    ")\n",
    "raw = mne.io.read_raw_fif(sample_data_raw_file, verbose=False)\n",
    "events_file = os.path.join(\n",
    "    sample_data_folder, \"MEG\", \"sample\", \"sample_audvis_filt-0-40_raw-eve.fif\"\n",
    ")\n",
    "events = mne.read_events(events_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotating bad spans of data\n",
    "\n",
    "The tutorial `tut-events-vs-annotations` describes how\n",
    ":class:`~mne.Annotations` can be read from embedded events in the raw\n",
    "recording file, and `tut-annotate-raw` describes in detail how to\n",
    "interactively annotate a :class:`~mne.io.Raw` data object. Here, we focus on\n",
    "best practices for annotating *bad* data spans so that they will be excluded\n",
    "from your analysis pipeline.\n",
    "\n",
    "\n",
    "### The ``reject_by_annotation`` parameter\n",
    "\n",
    "In the interactive ``raw.plot()`` window, the annotation controls can be\n",
    "opened by pressing :kbd:`a`. Here, new annotation labels can be created or\n",
    "existing annotation labels can be selected for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = raw.plot()\n",
    "fig.fake_keypress(\"a\")  # Simulates user pressing 'a' on the keyboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that you need to add a description first to start with\n",
    "marking spans (Push the button \"Add Description\" and enter the description).\n",
    "You can use any description you like, but annotations marking spans that\n",
    "should be excluded from the analysis pipeline should all begin with \"BAD\" or\n",
    "\"bad\" (e.g., \"bad_cough\", \"bad-eyes-closed\", \"bad door slamming\", etc). When\n",
    "this practice is followed, many processing steps in MNE-Python will\n",
    "automatically exclude the \"bad\"-labelled spans of data; this behavior is\n",
    "controlled by a parameter ``reject_by_annotation`` that can be found in many\n",
    "MNE-Python functions or class constructors, including:\n",
    "\n",
    "- creation of epoched data from continuous data (:class:`mne.Epochs`)\n",
    "- many methods of the independent components analysis class\n",
    "  (:class:`mne.preprocessing.ICA`)\n",
    "- functions for finding heartbeat and blink artifacts\n",
    "  (:func:`~mne.preprocessing.find_ecg_events`,\n",
    "  :func:`~mne.preprocessing.find_eog_events`)\n",
    "- covariance computations (:func:`mne.compute_raw_covariance`)\n",
    "- power spectral density computation (:meth:`mne.io.Raw.compute_psd`)\n",
    "\n",
    "For example, when creating epochs from continuous data, if\n",
    "``reject_by_annotation=True`` the :class:`~mne.Epochs` constructor will drop\n",
    "any epoch that partially or fully overlaps with an annotated span that begins\n",
    "with \"bad\".\n",
    "\n",
    "\n",
    "### Generating annotations programmatically\n",
    "\n",
    "The `tut-artifact-overview` tutorial introduced the artifact detection\n",
    "functions :func:`~mne.preprocessing.find_eog_events` and\n",
    ":func:`~mne.preprocessing.find_ecg_events` (although that tutorial mostly\n",
    "relied on their higher-level wrappers\n",
    ":func:`~mne.preprocessing.create_eog_epochs` and\n",
    ":func:`~mne.preprocessing.create_ecg_epochs`). Here, for demonstration\n",
    "purposes, we make use of the lower-level artifact detection function to get\n",
    "an events array telling us where the blinks are, then automatically add\n",
    "\"bad_blink\" annotations around them (this is not necessary when using\n",
    ":func:`~mne.preprocessing.create_eog_epochs`, it is done here just to show\n",
    "how annotations are added non-interactively). We'll start the annotations\n",
    "250 ms before the blink and end them 250 ms after it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eog_events = mne.preprocessing.find_eog_events(raw)\n",
    "onsets = eog_events[:, 0] / raw.info[\"sfreq\"] - 0.25\n",
    "durations = [0.5] * len(eog_events)\n",
    "descriptions = [\"bad blink\"] * len(eog_events)\n",
    "blink_annot = mne.Annotations(\n",
    "    onsets, durations, descriptions, orig_time=raw.info[\"meas_date\"]\n",
    ")\n",
    "raw.set_annotations(blink_annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can confirm that the annotations are centered on the EOG events. Since\n",
    "blinks are usually easiest to see in the EEG channels, we'll only plot EEG\n",
    "here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_picks = mne.pick_types(raw.info, meg=False, eeg=True)\n",
    "raw.plot(events=eog_events, order=eeg_picks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the section `tut-section-programmatic-annotations` for more details\n",
    "on creating annotations programmatically.\n",
    "\n",
    "### Detecting and annotating breaks\n",
    "Another useful function, albeit not related to artifact detection *per se*,\n",
    "is `mne.preprocessing.annotate_break`: It will generate annotations for\n",
    "segments of the data where no existing annotations (or, alternatively:\n",
    "events) can be found. It can therefore be used to automatically detect and\n",
    "mark breaks, e.g. between experimental blocks, when recording continued.\n",
    "\n",
    "For the sake of this example, let's assume an experiment consisting of two\n",
    "blocks, the first one stretching from 30 to 90, and the second from 120 to\n",
    "180 seconds. We'll mark these blocks by annotations, and then use\n",
    "`mne.preprocessing.annotate_break` to detect and annotate any breaks.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>We need to take ``raw.first_time`` into account, otherwise the\n",
    "          onsets will be incorrect!</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onsets = [raw.first_time + 30, raw.first_time + 180]\n",
    "durations = [60, 60]\n",
    "descriptions = [\"block_1\", \"block_2\"]\n",
    "\n",
    "block_annots = mne.Annotations(\n",
    "    onset=onsets,\n",
    "    duration=durations,\n",
    "    description=descriptions,\n",
    "    orig_time=raw.info[\"meas_date\"],\n",
    ")\n",
    "raw.set_annotations(raw.annotations + block_annots)  # add to existing\n",
    "raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now detect break periods. We can control how far the break annotations shall\n",
    "expand toward both ends of each break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_annots = mne.preprocessing.annotate_break(\n",
    "    raw=raw,\n",
    "    min_break_duration=20,  # consider segments of at least 20 s duration\n",
    "    t_start_after_previous=5,  # start annotation 5 s after end of previous one\n",
    "    t_stop_before_next=2,  # stop annotation 2 s before beginning of next one\n",
    ")\n",
    "\n",
    "raw.set_annotations(raw.annotations + break_annots)  # add to existing\n",
    "raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that 3 segments have been annotated as ``BAD_break``:\n",
    "\n",
    "- the first one starting with the beginning of the recording and ending 2\n",
    "  seconds before the beginning of block 1 (due to ``t_stop_before_next=2``),\n",
    "- the second one starting 5 seconds after block 1 has ended, and ending 2\n",
    "  seconds before the beginning of block 2 (``t_start_after_previous=5``,\n",
    "  ``t_stop_before_next=2``),\n",
    "- and the last one starting 5 seconds after block 2 has ended\n",
    "  (``t_start_after_previous=5``) and continuing until the end of the\n",
    "  recording.\n",
    "\n",
    "You can also see that only the ``block_1`` and ``block_2`` annotations\n",
    "were considered in the detection of the break periods â€“ the EOG annotations\n",
    "were simply ignored. This is because, by default,\n",
    "`~mne.preprocessing.annotate_break` ignores all annotations starting with\n",
    "``'bad'``. You can control this behavior via the ``ignore`` parameter.\n",
    "\n",
    "It is also possible to perform break period detection based on an array\n",
    "of events: simply pass the array via the ``events`` parameter. Existing\n",
    "annotations in the raw data will be ignored in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep some button press events (code 32) for this demonstration\n",
    "events_subset = events[events[:, -1] == 32]\n",
    "# drop the first and last few events\n",
    "events_subset = events_subset[3:-3]\n",
    "\n",
    "break_annots = mne.preprocessing.annotate_break(\n",
    "    raw=raw,\n",
    "    events=events_subset,  # passing events will ignore existing annotations\n",
    "    min_break_duration=25,  # pick a longer break duration this time\n",
    ")\n",
    "\n",
    "# replace existing annotations (otherwise it becomes difficult to see any\n",
    "# effects in the plot!)\n",
    "raw.set_annotations(break_annots)\n",
    "raw.plot(events=events_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejecting Epochs based on peak-to-peak channel amplitude\n",
    "\n",
    "Besides \"bad\" annotations, the :class:`mne.Epochs` class constructor has\n",
    "another means of rejecting epochs, based on signal amplitude thresholds for\n",
    "each channel type. In the `overview tutorial\n",
    "<tut-section-overview-epoching>` we saw an example of this: setting maximum\n",
    "acceptable peak-to-peak amplitudes for each channel type in an epoch, using\n",
    "the ``reject`` parameter. There is also a related parameter, ``flat``, that\n",
    "can be used to set *minimum* acceptable peak-to-peak amplitudes for each\n",
    "channel type in an epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_criteria = dict(\n",
    "    mag=3000e-15,  # 3000 fT\n",
    "    grad=3000e-13,  # 3000 fT/cm\n",
    "    eeg=100e-6,  # 100 ÂµV\n",
    "    eog=200e-6,\n",
    ")  # 200 ÂµV\n",
    "\n",
    "flat_criteria = dict(mag=1e-15, grad=1e-13, eeg=1e-6)  # 1 fT  # 1 fT/cm  # 1 ÂµV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values that are appropriate are dataset- and hardware-dependent, so some\n",
    "trial-and-error may be necessary to find the correct balance between data\n",
    "quality and loss of power due to too many dropped epochs. Here, we've set the\n",
    "rejection criteria to be fairly stringent, for illustration purposes.\n",
    "\n",
    "Two additional parameters, ``reject_tmin`` and ``reject_tmax``, are used to\n",
    "set the temporal window in which to calculate peak-to-peak amplitude for the\n",
    "purposes of epoch rejection. These default to the same ``tmin`` and ``tmax``\n",
    "of the entire epoch. As one example, if you wanted to only apply the\n",
    "rejection thresholds to the portion of the epoch that occurs *before* the\n",
    "event marker around which the epoch is created, you could set\n",
    "``reject_tmax=0``. A summary of the causes of rejected epochs can be\n",
    "generated with the :meth:`~mne.Epochs.plot_drop_log` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.set_annotations(blink_annot)  # restore the EOG annotations\n",
    "epochs = mne.Epochs(\n",
    "    raw,\n",
    "    events,\n",
    "    tmin=-0.2,\n",
    "    tmax=0.5,\n",
    "    reject_tmax=0,\n",
    "    reject=reject_criteria,\n",
    "    flat=flat_criteria,\n",
    "    reject_by_annotation=False,\n",
    "    preload=True,\n",
    ")\n",
    "epochs.plot_drop_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we've passed ``reject_by_annotation=False`` above, in order to\n",
    "isolate the effects of the rejection thresholds. If we re-run the epoching\n",
    "with ``reject_by_annotation=True`` (the default) we see that the rejections\n",
    "due to EEG and EOG channels have disappeared (suggesting that those channel\n",
    "fluctuations were probably blink-related, and were subsumed by rejections\n",
    "based on the \"bad blink\" label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.Epochs(\n",
    "    raw,\n",
    "    events,\n",
    "    tmin=-0.2,\n",
    "    tmax=0.5,\n",
    "    reject_tmax=0,\n",
    "    reject=reject_criteria,\n",
    "    flat=flat_criteria,\n",
    "    preload=True,\n",
    ")\n",
    "epochs.plot_drop_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More importantly, note that *many* more epochs are rejected (~12.2% instead\n",
    "of ~2.5%) when rejecting based on the blink labels, underscoring why it is\n",
    "usually desirable to repair artifacts rather than exclude them.\n",
    "\n",
    "The :meth:`~mne.Epochs.plot_drop_log` method is a visualization of an\n",
    ":class:`~mne.Epochs` attribute, namely ``epochs.drop_log``, which stores\n",
    "empty lists for retained epochs and lists of strings for dropped epochs, with\n",
    "the strings indicating the reason(s) why the epoch was dropped. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epochs.drop_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it should be noted that \"dropped\" epochs are not necessarily deleted\n",
    "from the :class:`~mne.Epochs` object right away. Above, we forced the\n",
    "dropping to happen when we created the :class:`~mne.Epochs` object by using\n",
    "the ``preload=True`` parameter. If we had not done that, the\n",
    ":class:`~mne.Epochs` object would have been `memory-mapped`_ (not loaded into\n",
    "RAM), in which case the criteria for dropping epochs are stored, and the\n",
    "actual dropping happens when the :class:`~mne.Epochs` data are finally loaded\n",
    "and used. There are several ways this can get triggered, such as:\n",
    "\n",
    "- explicitly loading the data into RAM with the :meth:`~mne.Epochs.load_data`\n",
    "  method\n",
    "- plotting the data (:meth:`~mne.Epochs.plot`,\n",
    "  :meth:`~mne.Epochs.plot_image`, etc)\n",
    "- using the :meth:`~mne.Epochs.average` method to create an\n",
    "  :class:`~mne.Evoked` object\n",
    "\n",
    "You can also trigger dropping with the :meth:`~mne.Epochs.drop_bad` method;\n",
    "if ``reject`` and/or ``flat`` criteria have already been provided to the\n",
    "epochs constructor, :meth:`~mne.Epochs.drop_bad` can be used without\n",
    "arguments to simply delete the epochs already marked for removal (if the\n",
    "epochs have already been dropped, nothing further will happen):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.drop_bad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if rejection thresholds were not originally given to the\n",
    ":class:`~mne.Epochs` constructor, they can be passed to\n",
    ":meth:`~mne.Epochs.drop_bad` later instead; this can also be a way of\n",
    "imposing progressively more stringent rejection criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stronger_reject_criteria = dict(\n",
    "    mag=2000e-15,  # 2000 fT\n",
    "    grad=2000e-13,  # 2000 fT/cm\n",
    "    eeg=100e-6,  # 100 ÂµV\n",
    "    eog=100e-6,\n",
    ")  # 100 ÂµV\n",
    "\n",
    "epochs.drop_bad(reject=stronger_reject_criteria)\n",
    "print(epochs.drop_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejecting Epochs using callables (functions)\n",
    "\n",
    "Sometimes it is useful to reject epochs based criteria other than\n",
    "peak-to-peak amplitudes. For example, we might want to reject epochs\n",
    "based on the maximum or minimum amplitude of a channel.\n",
    "In this case, the `mne.Epochs.drop_bad` function also accepts\n",
    "callables (functions) in the ``reject`` and ``flat`` parameters. This\n",
    "allows us to define functions to reject epochs based on our desired criteria.\n",
    "\n",
    "Let's begin by generating Epoch data with large artifacts in one eeg channel\n",
    "in order to demonstrate the versatility of this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.crop(0, 5)\n",
    "raw.del_proj()\n",
    "chans = raw.info[\"ch_names\"][-5:-1]\n",
    "raw.pick(chans)\n",
    "data = raw.get_data()\n",
    "\n",
    "new_data = data\n",
    "new_data[0, 180:200] *= 1e3\n",
    "new_data[0, 460:580] += 1e-3\n",
    "edit_raw = mne.io.RawArray(new_data, raw.info)\n",
    "\n",
    "# Create fixed length epochs of 1 second\n",
    "events = mne.make_fixed_length_events(edit_raw, id=1, duration=1.0, start=0)\n",
    "epochs = mne.Epochs(edit_raw, events, tmin=0, tmax=1, baseline=None)\n",
    "epochs.plot(scalings=dict(eeg=50e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have two large artifacts in the first channel. One large\n",
    "spike in amplitude and one large increase in amplitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to reject the epoch containing the spike in amplitude based on the\n",
    "# maximum amplitude of the first channel. Please note that the callable in\n",
    "# ``reject`` must return a (good, reason) tuple. Where the good must be bool\n",
    "# and reason must be a str, list, or tuple where each entry is a str.\n",
    "\n",
    "# Custom rejection function\n",
    "def custom_reject(epoch_data):\n",
    "    max_amplitude = np.max(epoch_data[0, :])  # Get the maximum amplitude of the first channel\n",
    "    if max_amplitude > 1e-2:  # Define your threshold\n",
    "        return False, \"max amp\"\n",
    "    return True, \"\"\n",
    "\n",
    "# Load your raw data and events here (assuming 'edit_raw' and 'events' are predefined)\n",
    "epochs = mne.Epochs(\n",
    "    edit_raw,\n",
    "    events,\n",
    "    tmin=0,\n",
    "    tmax=1,\n",
    "    baseline=None,\n",
    "    preload=True,\n",
    ")\n",
    "\n",
    "# Apply custom rejection logic to each epoch\n",
    "to_reject = []\n",
    "reasons = []\n",
    "for i, epoch in enumerate(epochs):\n",
    "    good, reason = custom_reject(epoch)\n",
    "    if not good:\n",
    "        to_reject.append(i)\n",
    "        reasons.append(reason)\n",
    "\n",
    "# Drop the epochs that do not pass the custom rejection criteria\n",
    "epochs.drop(to_reject, reason=\"max amp\")\n",
    "\n",
    "# Plot the clean epochs\n",
    "epochs.plot(scalings=dict(eeg=50e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the epoch containing the spike in amplitude was rejected for having a\n",
    "maximum amplitude greater than 1e-2 Volts. Notice the use of the ``any()``\n",
    "function to check if any of the channels exceeded the threshold. We could\n",
    "have also used the ``all()`` function to check if all channels exceeded the\n",
    "threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let's try to reject the epoch containing the increase in amplitude\n",
    "# using the median.\n",
    "\n",
    "# Custom rejection function based on median amplitude\n",
    "def custom_reject_median(epoch_data):\n",
    "    median_amplitude = np.median(epoch_data, axis=1)  # Calculate the median amplitude for each channel\n",
    "    if (median_amplitude > 1e-4).any():  # Define your threshold\n",
    "        return False, \"median amp\"\n",
    "    return True, \"\"\n",
    "\n",
    "# Load your raw data and events here (assuming 'edit_raw' and 'events' are predefined)\n",
    "epochs = mne.Epochs(\n",
    "    edit_raw,\n",
    "    events,\n",
    "    tmin=0,\n",
    "    tmax=1,\n",
    "    baseline=None,\n",
    "    preload=True,\n",
    ")\n",
    "\n",
    "# Apply custom rejection logic to each epoch\n",
    "to_reject = []\n",
    "reasons = []\n",
    "for i, epoch in enumerate(epochs):\n",
    "    good, reason = custom_reject_median(epoch)\n",
    "    if not good:\n",
    "        to_reject.append(i)\n",
    "        reasons.append(reason)\n",
    "\n",
    "# Drop the epochs that do not pass the custom rejection criteria\n",
    "epochs.drop(to_reject, reason=\"median amp\")\n",
    "\n",
    "# Plot the clean epochs\n",
    "epochs.plot(scalings=dict(eeg=50e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try to reject both epochs using a combination of the maximum\n",
    "and median. We'll define a custom function and use boolean operators to\n",
    "combine the two criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom rejection function based on max and median amplitude\n",
    "def reject_criteria(epoch_data):\n",
    "    max_condition = np.max(epoch_data, axis=1) > 1e-2\n",
    "    median_condition = np.median(epoch_data, axis=1) > 1e-4\n",
    "    return max_condition.any() or median_condition.any()\n",
    "\n",
    "# Load your raw data and events here (assuming 'edit_raw' and 'events' are predefined)\n",
    "epochs = mne.Epochs(\n",
    "    edit_raw,\n",
    "    events,\n",
    "    tmin=0,\n",
    "    tmax=1,\n",
    "    baseline=None,\n",
    "    preload=True,\n",
    ")\n",
    "\n",
    "# List to keep track of indices of epochs to reject\n",
    "to_reject = []\n",
    "\n",
    "# Iterate over each epoch and apply the custom rejection function\n",
    "for i, epoch in enumerate(epochs):\n",
    "    if reject_criteria(epoch):\n",
    "        to_reject.append(i)\n",
    "\n",
    "# Drop the epochs that do not pass the custom rejection criteria\n",
    "epochs.drop(to_reject, reason=\"custom rejection\")\n",
    "\n",
    "# Plot the clean epochs\n",
    "epochs.plot(scalings=dict(eeg=50e-5), events=epochs.events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a complementary Python module, the `autoreject package`_, uses\n",
    "machine learning to find optimal rejection criteria, and is designed to\n",
    "integrate smoothly with MNE-Python workflows. This can be a considerable\n",
    "time-saver when working with heterogeneous datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filtering and resampling data\n",
    "\n",
    "This tutorial covers filtering and resampling, and gives examples of how\n",
    "filtering can be used for artifact repair.\n",
    "\n",
    "We begin as always by importing the necessary Python modules and loading some\n",
    "`example data <sample-dataset>`. We'll also crop the data to 60 seconds\n",
    "(to save memory on the documentation server):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "\n",
    "sample_data_folder = mne.datasets.sample.data_path()\n",
    "sample_data_raw_file = os.path.join(\n",
    "    sample_data_folder, \"MEG\", \"sample\", \"sample_audvis_raw.fif\"\n",
    ")\n",
    "raw = mne.io.read_raw_fif(sample_data_raw_file)\n",
    "# use just 60 seconds of data and mag channels, to save memory\n",
    "raw.crop(0, 60).pick(picks=[\"mag\", \"stim\"]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background on filtering\n",
    "\n",
    "A filter removes or attenuates parts of a signal. Usually, filters act on\n",
    "specific *frequency ranges* of a signal â€” for example, suppressing all\n",
    "frequency components above or below a certain cutoff value. There are *many*\n",
    "ways of designing digital filters; see `disc-filtering` for a longer\n",
    "discussion of the various approaches to filtering physiological signals in\n",
    "MNE-Python.\n",
    "\n",
    "\n",
    "## Repairing artifacts by filtering\n",
    "\n",
    "Artifacts that are restricted to a narrow frequency range can sometimes\n",
    "be repaired by filtering the data. Two examples of frequency-restricted\n",
    "artifacts are slow drifts and power line noise. Here we illustrate how each\n",
    "of these can be repaired by filtering.\n",
    "\n",
    "\n",
    "### Slow drifts\n",
    "\n",
    "Low-frequency drifts in raw data can usually be spotted by plotting a fairly\n",
    "long span of data with the :meth:`~mne.io.Raw.plot` method, though it is\n",
    "helpful to disable channel-wise DC shift correction to make slow drifts\n",
    "more readily visible. Here we plot 60 seconds, showing all the magnetometer\n",
    "channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot(duration=60, proj=False, n_channels=len(raw.ch_names), remove_dc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A half-period of this slow drift appears to last around 10 seconds, so a full\n",
    "period would be 20 seconds, i.e., $\\frac{1}{20} \\mathrm{Hz}$. To be\n",
    "sure those components are excluded, we want our highpass to be *higher* than\n",
    "that, so let's try $\\frac{1}{10} \\mathrm{Hz}$ and $\\frac{1}{5}\n",
    "\\mathrm{Hz}$ filters to see which works best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cutoff in (0.1, 0.2):\n",
    "    raw_highpass = raw.copy().filter(l_freq=cutoff, h_freq=None)\n",
    "    with mne.viz.use_browser_backend(\"matplotlib\"):\n",
    "        fig = raw_highpass.plot(\n",
    "            duration=60, proj=False, n_channels=len(raw.ch_names), remove_dc=False\n",
    "        )\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    fig.suptitle(f\"High-pass filtered at {cutoff} Hz\", size=\"xx-large\", weight=\"bold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like 0.1 Hz was not quite high enough to fully remove the slow drifts.\n",
    "Notice that the text output summarizes the relevant characteristics of the\n",
    "filter that was created. If you want to visualize the filter, you can pass\n",
    "the same arguments used in the call to :meth:`raw.filter()\n",
    "<mne.io.Raw.filter>` above to the function :func:`mne.filter.create_filter`\n",
    "to get the filter parameters, and then pass the filter parameters to\n",
    ":func:`mne.viz.plot_filter`. :func:`~mne.filter.create_filter` also requires\n",
    "parameters ``data`` (a :class:`NumPy array <numpy.ndarray>`) and ``sfreq``\n",
    "(the sampling frequency of the data), so we'll extract those from our\n",
    ":class:`~mne.io.Raw` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_params = mne.filter.create_filter(\n",
    "    raw.get_data(), raw.info[\"sfreq\"], l_freq=0.2, h_freq=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the output is the same as when we applied this filter to the data\n",
    "using :meth:`raw.filter() <mne.io.Raw.filter>`. You can now pass the filter\n",
    "parameters (and the sampling frequency) to :func:`~mne.viz.plot_filter` to\n",
    "plot the filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_filter(filter_params, raw.info[\"sfreq\"], flim=(0.01, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power line noise\n",
    "\n",
    "Power line noise is an environmental artifact that manifests as persistent\n",
    "oscillations centered around the `AC power line frequency`_. Power line\n",
    "artifacts are easiest to see on plots of the spectrum, so we'll use\n",
    ":meth:`~mne.io.Raw.compute_psd` to get a\n",
    ":class:`~mne.time_frequency.Spectrum` object, and use its\n",
    ":meth:`~mne.time_frequency.Spectrum.plot` method to illustrate. We'll also\n",
    "write a little function that adds arrows to the spectrum plot to highlight\n",
    "the artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arrows(axes):\n",
    "    \"\"\"Add some arrows at 60 Hz and its harmonics.\"\"\"\n",
    "    for ax in axes:\n",
    "        freqs = ax.lines[-1].get_xdata()\n",
    "        psds = ax.lines[-1].get_ydata()\n",
    "        for freq in (60, 120, 180, 240):\n",
    "            idx = np.searchsorted(freqs, freq)\n",
    "            # get ymax of a small region around the freq. of interest\n",
    "            y = psds[(idx - 4) : (idx + 5)].max()\n",
    "            ax.arrow(\n",
    "                x=freqs[idx],\n",
    "                y=y + 18,\n",
    "                dx=0,\n",
    "                dy=-12,\n",
    "                color=\"red\",\n",
    "                width=0.1,\n",
    "                head_width=3,\n",
    "                length_includes_head=True,\n",
    "            )\n",
    "\n",
    "\n",
    "fig = raw.compute_psd(fmax=250).plot(\n",
    "    average=True, amplitude=False, picks=\"data\", exclude=\"bads\"\n",
    ")\n",
    "add_arrows(fig.axes[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be evident that MEG channels are more susceptible to this kind of\n",
    "interference than EEG that is recorded in the magnetically shielded room.\n",
    "Removing power-line noise can be done with a notch filter,\n",
    "applied directly to the :class:`~mne.io.Raw` object, specifying an array of\n",
    "frequencies to be attenuated. Since the EEG channels are relatively\n",
    "unaffected by the power line noise, we'll also specify a ``picks`` argument\n",
    "so that only the magnetometers and gradiometers get filtered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meg_picks = mne.pick_types(raw.info, meg=True)\n",
    "freqs = (60, 120, 180, 240)\n",
    "raw_notch = raw.copy().notch_filter(freqs=freqs, picks=meg_picks)\n",
    "for title, data in zip([\"Un\", \"Notch \"], [raw, raw_notch]):\n",
    "    fig = data.compute_psd(fmax=250).plot(\n",
    "        average=True, amplitude=False, picks=\"data\", exclude=\"bads\"\n",
    "    )\n",
    "    fig.suptitle(f\"{title}filtered\", size=\"xx-large\", weight=\"bold\")\n",
    "    add_arrows(fig.axes[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`~mne.io.Raw.notch_filter` also has parameters to control the notch\n",
    "width, transition bandwidth and other aspects of the filter. See the\n",
    "docstring for details.\n",
    "\n",
    "It's also possible to try to use a spectrum fitting routine to notch filter.\n",
    "In principle it can automatically detect the frequencies to notch, but our\n",
    "implementation generally does not do so reliably, so we specify the\n",
    "frequencies to remove instead, and it does a good job of removing the\n",
    "line noise at those frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_notch_fit = raw.copy().notch_filter(\n",
    "    freqs=freqs, picks=meg_picks, method=\"spectrum_fit\", filter_length=\"10s\"\n",
    ")\n",
    "for title, data in zip([\"Un\", \"spectrum_fit \"], [raw, raw_notch_fit]):\n",
    "    fig = data.compute_psd(fmax=250).plot(\n",
    "        average=True, amplitude=False, picks=\"data\", exclude=\"bads\"\n",
    "    )\n",
    "    fig.suptitle(f\"{title}filtered\", size=\"xx-large\", weight=\"bold\")\n",
    "    add_arrows(fig.axes[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "EEG and MEG recordings are notable for their high temporal precision, and are\n",
    "often recorded with sampling rates around 1000 Hz or higher. This is good\n",
    "when precise timing of events is important to the experimental design or\n",
    "analysis plan, but also consumes more memory and computational resources when\n",
    "processing the data. In cases where high-frequency components of the signal\n",
    "are not of interest and precise timing is not needed (e.g., computing EOG or\n",
    "ECG projectors on a long recording), downsampling the signal can be a useful\n",
    "time-saver.\n",
    "\n",
    "In MNE-Python, the resampling methods (:meth:`raw.resample()\n",
    "<mne.io.Raw.resample>`, :meth:`epochs.resample() <mne.Epochs.resample>` and\n",
    ":meth:`evoked.resample() <mne.Evoked.resample>`) apply a low-pass filter to\n",
    "the signal to avoid `aliasing`_, so you don't need to explicitly filter it\n",
    "yourself first. This built-in filtering that happens when using\n",
    ":meth:`raw.resample() <mne.io.Raw.resample>`, :meth:`epochs.resample()\n",
    "<mne.Epochs.resample>`, or :meth:`evoked.resample() <mne.Evoked.resample>` is\n",
    "a brick-wall filter applied in the frequency domain at the `Nyquist\n",
    "frequency`_ of the desired new sampling rate. This can be clearly seen in the\n",
    "PSD plot, where a dashed vertical line indicates the filter cutoff; the\n",
    "original data had an existing lowpass at around 172 Hz (see\n",
    "``raw.info['lowpass']``), and the data resampled from ~600 Hz to 200 Hz gets\n",
    "automatically lowpass filtered at 100 Hz (the `Nyquist frequency`_ for a\n",
    "target rate of 200 Hz):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_downsampled = raw.copy().resample(sfreq=200)\n",
    "# choose n_fft for Welch PSD to make frequency axes similar resolution\n",
    "n_ffts = [4096, int(round(4096 * 200 / raw.info[\"sfreq\"]))]\n",
    "fig, axes = plt.subplots(2, 1, sharey=True, layout=\"constrained\", figsize=(10, 6))\n",
    "for ax, data, title, n_fft in zip(\n",
    "    axes, [raw, raw_downsampled], [\"Original\", \"Downsampled\"], n_ffts\n",
    "):\n",
    "    fig = data.compute_psd(n_fft=n_fft).plot(\n",
    "        average=True, amplitude=False, picks=\"data\", exclude=\"bads\", axes=ax\n",
    "    )\n",
    "    ax.set(title=title, xlim=(0, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, MNE-Python resamples using ``method=\"fft\"``, which performs FFT-based\n",
    "resampling via :func:`scipy.signal.resample`. While efficient and good for most\n",
    "biological signals, it has two main potential drawbacks:\n",
    "\n",
    "1. It assumes periodicity of the signal. We try to overcome this with appropriate\n",
    "   signal padding, but some signal leakage may still occur.\n",
    "2. It treats the entire signal as a single block. This means that in general effects\n",
    "   are not guaranteed to be localized in time, though in practice they often are.\n",
    "\n",
    "Alternatively, resampling can be performed using ``method=\"polyphase\"`` instead.\n",
    "This uses :func:`scipy.signal.resample_poly` under the hood, which in turn utilizes\n",
    "a three-step process to resample signals (see :func:`scipy.signal.upfirdn` for\n",
    "details). This process guarantees that each resampled output value is only affected by\n",
    "input values within a limited range. In other words, output values are guaranteed to\n",
    "be a result of a specific set of input values.\n",
    "\n",
    "In general, using ``method=\"polyphase\"`` can also be faster than ``method=\"fft\"`` in\n",
    "cases where the desired sampling rate is an integer factor different from the input\n",
    "sampling rate. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ffts = [4096, 2048]  # factor of 2 smaller n_fft\n",
    "raw_downsampled_poly = raw.copy().resample(\n",
    "    sfreq=raw.info[\"sfreq\"] / 2.0,\n",
    "    npad='auto',\n",
    "    window='boxcar',\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, sharey=True, constrained_layout=True, figsize=(10, 6))\n",
    "for ax, data, title, n_fft in zip(\n",
    "    axes, [raw, raw_downsampled_poly], [\"Original\", \"Downsampled (polyphase)\"], n_ffts\n",
    "):\n",
    "    data.compute_psd(n_fft=n_fft).plot(\n",
    "        average=True, amplitude=False, picks=\"data\", exclude=\"bads\", axes=ax\n",
    "    )\n",
    "    ax.set(title=title, xlim=(0, 300))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because resampling involves filtering, there are some pitfalls to resampling\n",
    "at different points in the analysis stream:\n",
    "\n",
    "- Performing resampling on :class:`~mne.io.Raw` data (*before* epoching) will\n",
    "  negatively affect the temporal precision of Event arrays, by causing\n",
    "  `jitter`_ in the event timing. This reduced temporal precision will\n",
    "  propagate to subsequent epoching operations.\n",
    "\n",
    "- Performing resampling *after* epoching can introduce edge artifacts *on\n",
    "  every epoch*, whereas filtering the :class:`~mne.io.Raw` object will only\n",
    "  introduce artifacts at the start and end of the recording (which is often\n",
    "  far enough from the first and last epochs to have no affect on the\n",
    "  analysis).\n",
    "\n",
    "The following section suggests best practices to mitigate both of these\n",
    "issues.\n",
    "\n",
    "\n",
    "### Best practices\n",
    "\n",
    "To avoid the reduction in temporal precision of events that comes with\n",
    "resampling a :class:`~mne.io.Raw` object, and also avoid the edge artifacts\n",
    "that come with filtering an :class:`~mne.Epochs` or :class:`~mne.Evoked`\n",
    "object, the best practice is to:\n",
    "\n",
    "1. low-pass filter the :class:`~mne.io.Raw` data at or below\n",
    "   $\\frac{1}{3}$ of the desired sample rate, then\n",
    "\n",
    "2. decimate the data after epoching, by either passing the ``decim``\n",
    "   parameter to the :class:`~mne.Epochs` constructor, or using the\n",
    "   :meth:`~mne.Epochs.decimate` method after the :class:`~mne.Epochs` have\n",
    "   been created.\n",
    "\n",
    "<div class=\"alert alert-danger\"><h4>Warning</h4><p>The recommendation for setting the low-pass corner frequency at\n",
    "   $\\frac{1}{3}$ of the desired sample rate is a fairly safe rule of\n",
    "   thumb based on the default settings in :meth:`raw.filter()\n",
    "   <mne.io.Raw.filter>` (which are different from the filter settings used\n",
    "   inside the :meth:`raw.resample() <mne.io.Raw.resample>` method). If you\n",
    "   use a customized lowpass filter (specifically, if your transition\n",
    "   bandwidth is wider than 0.5Ã— the lowpass cutoff), downsampling to 3Ã— the\n",
    "   lowpass cutoff may still not be enough to avoid `aliasing`_, and\n",
    "   MNE-Python will not warn you about it (because the :class:`raw.info\n",
    "   <mne.Info>` object only keeps track of the lowpass cutoff, not the\n",
    "   transition bandwidth). Conversely, if you use a steeper filter, the\n",
    "   warning may be too sensitive. If you are unsure, plot the PSD of your\n",
    "   filtered data *before decimating* and ensure that there is no content in\n",
    "   the frequencies above the `Nyquist frequency`_ of the sample rate you'll\n",
    "   end up with *after* decimation.</p></div>\n",
    "\n",
    "Note that this method of manually filtering and decimating is exact only when\n",
    "the original sampling frequency is an integer multiple of the desired new\n",
    "sampling frequency. Since the sampling frequency of our example data is\n",
    "600.614990234375 Hz, ending up with a specific sampling frequency like (say)\n",
    "90 Hz will not be possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_sfreq = raw.info[\"sfreq\"]\n",
    "desired_sfreq = 90  # Hz\n",
    "decim = np.round(current_sfreq / desired_sfreq).astype(int)\n",
    "obtained_sfreq = current_sfreq / decim\n",
    "lowpass_freq = obtained_sfreq / 3.0\n",
    "\n",
    "raw_filtered = raw.copy().filter(l_freq=None, h_freq=lowpass_freq)\n",
    "events = mne.find_events(raw_filtered)\n",
    "epochs = mne.Epochs(raw_filtered, events, decim=decim)\n",
    "\n",
    "print(\n",
    "    \"desired sampling frequency was {} Hz; decim factor of {} yielded an \"\n",
    "    \"actual sampling frequency of {} Hz.\".format(\n",
    "        desired_sfreq, decim, epochs.info[\"sfreq\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If for some reason you cannot follow the above-recommended best practices,\n",
    "you should at the very least either:\n",
    "\n",
    "1. resample the data *after* epoching, and make your epochs long enough that\n",
    "   edge effects from the filtering do not affect the temporal span of the\n",
    "   epoch that you hope to analyze / interpret; or\n",
    "\n",
    "2. perform resampling on the :class:`~mne.io.Raw` object and its\n",
    "   corresponding Events array *simultaneously* so that they stay more or less\n",
    "   in synch. This can be done by passing the Events array as the\n",
    "   ``events`` parameter to :meth:`raw.resample() <mne.io.Raw.resample>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Repairing artifacts with regression\n",
    "\n",
    "This tutorial covers removal of artifacts using regression as in Gratton et al.\n",
    "(1983) :footcite:`GrattonEtAl1983` and Croft & Barry (2000)\n",
    ":footcite:`CroftBarry2000`.\n",
    "\n",
    "Generally speaking, artifacts that result in time waveforms on the sensors\n",
    "that are accurately reflected by some reference signal can be removed by\n",
    "regression. Blink artifacts captured by bipolar EOG channels provide a good\n",
    "example of this, so we will demonstrate this here.\n",
    "\n",
    "Although ECG signals are well captured by bipolar ECG electrodes,\n",
    "regression-based removal of ECG artifacts usually does not work very well.\n",
    "This is likely because the heart acts like a rotating dipole, and\n",
    "therefore the ECG channel time waveform recorded from the ECG electrode sites\n",
    "does not reflect the same temporal dynamics that manifest at each MEG channel\n",
    "(obtained by sampling some component of the related magnetic vector field).\n",
    "Other approaches like `ICA <tut-artifact-ica>` or\n",
    "`SSP <tut-artifact-ssp>` will likely work better for ECG.\n",
    "\n",
    "Furthermore, regression approaches are usually performed in situations where\n",
    "there are few channels available, and removing an entire signal component is\n",
    "undesirable. Hence, most articles on the topic concern EEG and it is\n",
    "unusual to see the technique applied to MEG. For this reason, we will restrict\n",
    "the analysis in this tutorial to EEG data only.\n",
    "\n",
    "\n",
    "## Prepare the data\n",
    "\n",
    "We begin as always by importing the necessary Python modules and loading some\n",
    "data. The `MNE-Sample <sample-dataset>` dataset has some clear, large\n",
    "blink artifacts, especially during the presentation of visual stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "from mne.preprocessing import EOGRegression\n",
    "\n",
    "data_path = mne.datasets.sample.data_path()\n",
    "raw_fname = data_path / \"MEG\" / \"sample\" / \"sample_audvis_raw.fif\"\n",
    "raw = mne.io.read_raw_fif(raw_fname)\n",
    "raw.pick([\"eeg\", \"eog\", \"stim\"])\n",
    "raw.load_data()\n",
    "\n",
    "# The regression technique works regardless of chosen reference. However, it is\n",
    "# important to choose a reference before proceeding with the analysis.\n",
    "raw.set_eeg_reference(\"average\")\n",
    "\n",
    "# Removing slow drifts makes for more stable regression coefficients. Make sure\n",
    "# to apply the same filter to both EEG and EOG channels!\n",
    "raw.filter(0.3, 40)\n",
    "\n",
    "# make epochs\n",
    "events = mne.find_events(raw)\n",
    "event_id = {\"visual/left\": 3, \"visual/right\": 4}\n",
    "epochs = mne.Epochs(raw, events, event_id=event_id, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the original data\n",
    "Let's first look at the `~mne.Evoked` data (average across epochs) without\n",
    "any corrections applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll try to keep a consistent ylim across figures\n",
    "plot_kwargs = dict(picks=\"all\", ylim=dict(eeg=(-10, 10), eog=(-5, 15)))\n",
    "\n",
    "# plot the evoked for the EEG and the EOG sensors\n",
    "fig = epochs.average(\"all\").plot(**plot_kwargs)\n",
    "fig.set_size_inches(6, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there is some EOG activity that is likely bleeding into the EEG\n",
    "evoked response. At around 250ms this becomes especially noticeable. Let's\n",
    "apply regression to subtract the EOG signal from the EEG signals to clean it\n",
    "up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and apply EOG regression\n",
    "Now, we'll compare the evoked response before and after we regress out the\n",
    "EOG signal. First, let's try plain regression, and then we'll explore more\n",
    "advanced techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform regression using the EOG sensor as independent variable and the EEG\n",
    "# sensors as dependent variables.\n",
    "model_plain = EOGRegression(picks=\"eeg\", picks_artifact=\"eog\").fit(epochs)\n",
    "fig = model_plain.plot(vlim=(None, 0.4))  # regression coefficients as topomap\n",
    "fig.set_size_inches(3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression coefficients show the linear relationship between each EEG\n",
    "sensor and the EOG sensor. Note that occipital sensors have a positive\n",
    "relationship, as we set a common-average reference when we loaded the data\n",
    "above.\n",
    "\n",
    "Now we are ready to use these coefficients to subtract the EOG signal from\n",
    "the EEG signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_clean_plain = model_plain.apply(epochs)\n",
    "# After regression, we should redo the baseline correction\n",
    "epochs_clean_plain.apply_baseline()\n",
    "# Show the evoked potential computed on the corrected data\n",
    "fig = epochs_clean_plain.average(\"all\").plot(**plot_kwargs)\n",
    "fig.set_size_inches(6, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressing the EOG signal out of the EEG signals has reduced the peak around\n",
    "250ms that was partly there because of eye artifacts.\n",
    "\n",
    "In the `MNE-Sample dataset <sample-dataset>`, there are no segments of\n",
    "data that are particularly unstable, so the basic form of regression produces\n",
    "robust coefficients. However, this may not be the case in every dataset, so\n",
    "let's explore some variations that may improve the estimation of the\n",
    "regression coefficients.\n",
    "\n",
    "One potential problem is that the EOG sensor does not only pick up eye\n",
    "artifacts, but also a bit of EEG signal. This means we are prone to\n",
    "overestimating the regression coefficients if the EOG sensors are placed too\n",
    "close to the EEG sensors. However, there is a correction we can apply to\n",
    "alleviate this.\n",
    "\n",
    "## Subtract the evoked response from the epoch data before regression\n",
    "Gratton et al. (1983) :footcite:`GrattonEtAl1983` suggest computing\n",
    "regression coefficients on epoch data with the evoked response subtracted\n",
    "out. The idea is that the EEG signal components relevant to the study are in\n",
    "the evoked, so by removing them, mostly noise components will be left. Since\n",
    "EOG artifacts are unlikely to be strictly time-locked to the stimulus onset,\n",
    "enough EOG information will likely remain to be able to estimate robust\n",
    "regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create epochs with the evoked subtracted out\n",
    "epochs_sub = epochs.copy().subtract_evoked()\n",
    "\n",
    "# perform regression\n",
    "model_sub = EOGRegression(picks=\"eeg\", picks_artifact=\"eog\").fit(epochs_sub)\n",
    "fig = model_sub.plot(vlim=(None, 0.4))\n",
    "fig.set_size_inches(3, 2)\n",
    "\n",
    "# apply the regression coefficients to the original epochs\n",
    "epochs_clean_sub = model_plain.apply(epochs).apply_baseline()\n",
    "fig = epochs_clean_sub.average(\"all\").plot(**plot_kwargs)\n",
    "fig.set_size_inches(6, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we obtain the same regression coefficients, even with the evoked\n",
    "removed from the epochs.\n",
    "\n",
    "## Create EOG evoked before regression\n",
    "It is advantageous to estimate the regression coefficients on a piece of data\n",
    "with lots of EOG activity. As EOG activity is typically much larger than EEG,\n",
    "the EOG artifacts will dominate the signal and the regression coefficients\n",
    "will reflect mostly the influence of the EOG. To amplify this effect, Croft &\n",
    "Barry (2000) :footcite:`CroftBarry2000` suggest creating epochs based on\n",
    "blink onsets and computing the evoked blink response. The averaging procedure\n",
    "will suppress EEG signals that are not strictly time-locked with the blink\n",
    "response. Ideally, one would create evokeds for both blinks and saccades, and\n",
    "create two separate regression models. However, we will restrict ourselves to\n",
    "just blink epochs, since MNE-Python contains an automated method for creating\n",
    "those.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>This is very similar to the approach taken by `SSP\n",
    "          <tut-artifact-ssp>`. The difference is that `SSP\n",
    "          <tut-artifact-ssp>` estimates signal components that are maximally\n",
    "          correlated with the artifact and removes any data along that\n",
    "          component (thereby reducing the rank of the non-EOG data), whereas\n",
    "          the regression approach uses the ongoing EOG signal to determine\n",
    "          how much data to remove (thereby not necessarily reducing the rank\n",
    "          of the non-EOG data). Generally, SSP tends to err on the side of\n",
    "          removing too much data, eliminating artifacts and true brain\n",
    "          signals alike, whereas regression will err on the side of not\n",
    "          removing enough, leaving some artifact signals still present in the\n",
    "          signal.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eog_epochs = mne.preprocessing.create_eog_epochs(raw)\n",
    "# We need to explicitly specify that we want to average the EOG channel too.\n",
    "eog_evoked = eog_epochs.average(\"all\")\n",
    "eog_evoked.plot(\"all\")\n",
    "fig.set_size_inches(6, 6)\n",
    "\n",
    "# perform regression on the evoked blink response\n",
    "model_evoked = EOGRegression(picks=\"eeg\", picks_artifact=\"eog\").fit(eog_evoked)\n",
    "fig = model_evoked.plot(vlim=(None, 0.4))\n",
    "fig.set_size_inches(3, 2)\n",
    "\n",
    "# apply the regression coefficients to the original epochs\n",
    "epochs_clean_evoked = model_evoked.apply(epochs).apply_baseline()\n",
    "fig = epochs_clean_evoked.average(\"all\").plot(**plot_kwargs)\n",
    "fig.set_size_inches(6, 6)\n",
    "\n",
    "# for good measure, also show the effect on the blink evoked\n",
    "eog_evoked_clean = model_evoked.apply(eog_evoked)\n",
    "eog_evoked_clean.apply_baseline()\n",
    "eog_evoked_clean.plot(\"all\")\n",
    "fig.set_size_inches(6, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that again, the regression weights have been correctly estimated.\n",
    "\n",
    "## Visualize the effect on raw data\n",
    "Once we have obtained robust regression weights, we can use them to apply the\n",
    "regression directly to raw, epoched, and evoked data. Here, we will use the\n",
    "regression weights obtained from the blink evoked and apply it to an instance\n",
    "of `~mne.io.Raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order = np.concatenate(\n",
    "    [  # plotting order: EOG first, then EEG\n",
    "        mne.pick_types(raw.info, meg=False, eog=True),\n",
    "        mne.pick_types(raw.info, meg=False, eeg=True),\n",
    "    ]\n",
    ")\n",
    "raw_kwargs = dict(\n",
    "    events=eog_epochs.events,\n",
    "    order=order,\n",
    "    start=13,\n",
    "    duration=3,\n",
    "    n_channels=10,\n",
    "    scalings=dict(eeg=50e-6, eog=250e-6),\n",
    ")\n",
    "\n",
    "# plot original data\n",
    "raw.plot(**raw_kwargs)\n",
    "\n",
    "# regress (using coefficients computed previously) and plot\n",
    "raw_clean = model_evoked.apply(raw)\n",
    "raw_clean.plot(**raw_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
